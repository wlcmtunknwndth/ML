{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQlcDy9BC5bE"
   },
   "source": [
    "# Методы машинного обучения – Контрольная работа №5\n",
    "\n",
    "# Нейронные сети CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKlRxa2EKcTu"
   },
   "source": [
    "Импортируем необходимые библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GCNmPhYuurZN"
   },
   "outputs": [],
   "source": [
    "# !pip install -q tfds-nightly\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\python312\\lib\\site-packages\\vboxapi-1.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n"
     ]
    }
   ],
   "source": [
    "!pip install -q tfds-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GXzQDlKzJII8"
   },
   "source": [
    "## Загрузка набора \"лошади или люди\" (horses_or_humans)\n",
    "\n",
    "Загрузим из __Tensorflow datasets__ набор данных `horses_or_humans`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wLwF99jXJII8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\horses_or_humans\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024f9bbde4e04d519f15452f114c3555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff0153ebd5bb45e0b03c1ff4808e20b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ds_train \u001b[38;5;241m=\u001b[39m \u001b[43mtfds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhorses_or_humans\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m df_train \u001b[38;5;241m=\u001b[39m tfds\u001b[38;5;241m.\u001b[39mas_dataframe(ds_train)\n\u001b[0;32m      3\u001b[0m df_train\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\load.py:327\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[0;32m    326\u001b[0m   download_and_prepare_kwargs \u001b[38;5;241m=\u001b[39m download_and_prepare_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m--> 327\u001b[0m   \u001b[43mdbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m as_dataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m   as_dataset_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:481\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[0;32m    479\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mread_from_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_dir)\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 481\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m   \u001b[38;5;66;03m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    487\u001b[0m   \u001b[38;5;66;03m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    488\u001b[0m   \u001b[38;5;66;03m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    489\u001b[0m   \u001b[38;5;66;03m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    490\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdownload_size \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownloaded_size\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1184\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1183\u001b[0m   optional_pipeline_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m-> 1184\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=unexpected-keyword-arg\u001b[39;49;00m\n\u001b[0;32m   1185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptional_pipeline_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[38;5;66;03m# TODO(tfds): Could be removed once all datasets are migrated.\u001b[39;00m\n\u001b[0;32m   1187\u001b[0m \u001b[38;5;66;03m# https://github.com/tensorflow/datasets/issues/2537\u001b[39;00m\n\u001b[0;32m   1188\u001b[0m \u001b[38;5;66;03m# Legacy mode (eventually convert list[SplitGeneratorLegacy] -> dict)\u001b[39;00m\n\u001b[0;32m   1189\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m split_builder\u001b[38;5;241m.\u001b[39mnormalize_legacy_split_generators(\n\u001b[0;32m   1190\u001b[0m     split_generators\u001b[38;5;241m=\u001b[39msplit_generators,\n\u001b[0;32m   1191\u001b[0m     generator_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_examples,\n\u001b[0;32m   1192\u001b[0m     is_beam\u001b[38;5;241m=\u001b[39m\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, BeamBasedBuilder),\n\u001b[0;32m   1193\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\image_classification\\horses_or_humans.py:61\u001b[0m, in \u001b[0;36mHorsesOrHumans._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_generators\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager):\n\u001b[1;32m---> 61\u001b[0m   train_path, test_path \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m_TRAIN_URL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_TEST_URL\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[0;32m     64\u001b[0m       tfds\u001b[38;5;241m.\u001b[39mcore\u001b[38;5;241m.\u001b[39mSplitGenerator(\n\u001b[0;32m     65\u001b[0m           name\u001b[38;5;241m=\u001b[39mtfds\u001b[38;5;241m.\u001b[39mSplit\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     69\u001b[0m           gen_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marchive\u001b[39m\u001b[38;5;124m\"\u001b[39m: dl_manager\u001b[38;5;241m.\u001b[39miter_archive(test_path)}),\n\u001b[0;32m     70\u001b[0m   ]\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:548\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# Add progress bar to follow the download state\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downloader\u001b[38;5;241m.\u001b[39mtqdm():\n\u001b[1;32m--> 548\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_promise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:766\u001b[0m, in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m all_promises \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(map_fn, all_inputs)  \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 766\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_promises\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Wait promises\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\nest.py:628\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    544\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    629\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    630\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1065\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \n\u001b[0;32m    970\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[1;32m-> 1065\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[0;32m   1067\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\nest_util.py:1105\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[0;32m   1101\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[0;32m   1104\u001b[0m     structure[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m-> 1105\u001b[0m     [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m entries],\n\u001b[0;32m   1106\u001b[0m     expand_composites\u001b[38;5;241m=\u001b[39mexpand_composites,\n\u001b[0;32m   1107\u001b[0m )\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:766\u001b[0m, in \u001b[0;36m_map_promise.<locals>.<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    764\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    765\u001b[0m all_promises \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(map_fn, all_inputs)  \u001b[38;5;66;03m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 766\u001b[0m res \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\u001b[38;5;28;01mlambda\u001b[39;00m p: \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, all_promises)  \u001b[38;5;66;03m# Wait promises\u001b[39;00m\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\promise\\promise.py:512\u001b[0m, in \u001b[0;36mPromise.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target()\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[1;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\promise\\promise.py:516\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_target_settled_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, _raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;66;03m# type: (bool) -> Any\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_settled_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_raise\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\promise\\promise.py:226\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _raise:\n\u001b[0;32m    225\u001b[0m     raise_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n\u001b[1;32m--> 226\u001b[0m     \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_traceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fulfillment_handler0\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m value\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\promise\\promise.py:87\u001b[0m, in \u001b[0;36mtry_catch\u001b[1;34m(handler, *args, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtry_catch\u001b[39m(handler, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# type: (Callable, Any, Any) -> Union[Tuple[Any, None], Tuple[None, Tuple[Exception, Optional[TracebackType]]]]\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 87\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43mhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     89\u001b[0m         tb \u001b[38;5;241m=\u001b[39m exc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:358\u001b[0m, in \u001b[0;36mDownloadManager._download.<locals>.<lambda>\u001b[1;34m(dl_result)\u001b[0m\n\u001b[0;32m    354\u001b[0m   future \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_downloader\u001b[38;5;241m.\u001b[39mdownload(\n\u001b[0;32m    355\u001b[0m       url, download_tmp_dir, verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verify_ssl)\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# Post-process the result\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mthen(\u001b[38;5;28;01mlambda\u001b[39;00m dl_result: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_register_or_validate_checksums\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=g-long-lambda\u001b[39;49;00m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputed_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_url_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchecksum_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:421\u001b[0m, in \u001b[0;36mDownloadManager._register_or_validate_checksums\u001b[1;34m(self, path, url, expected_url_info, computed_url_info, checksum_path, url_path)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m   \u001b[38;5;66;03m# Eventually validate checksums\u001b[39;00m\n\u001b[0;32m    405\u001b[0m   \u001b[38;5;66;03m# Note:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    411\u001b[0m   \u001b[38;5;66;03m#   download). This is expected as it might mean the downloaded file\u001b[39;00m\n\u001b[0;32m    412\u001b[0m   \u001b[38;5;66;03m#   was corrupted. Note: The tmp file isn't deleted to allow inspection.\u001b[39;00m\n\u001b[0;32m    413\u001b[0m   _validate_checksums(\n\u001b[0;32m    414\u001b[0m       url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    415\u001b[0m       path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    418\u001b[0m       force_checksums_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_force_checksums_validation,\n\u001b[0;32m    419\u001b[0m   )\n\u001b[1;32m--> 421\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rename_and_get_final_dl_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpected_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_url_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcomputed_url_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomputed_url_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchecksum_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:445\u001b[0m, in \u001b[0;36mDownloadManager._rename_and_get_final_dl_path\u001b[1;34m(self, url, path, expected_url_info, computed_url_info, checksum_path, url_path)\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Eventually rename the downloaded file if checksums were recorded.\"\"\"\u001b[39;00m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;66;03m# `path` can be:\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[38;5;66;03m# * Manually downloaded\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;66;03m# * (cached) checksum_path\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# * (cached) url_path\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;66;03m# * `tmp_dir/file` (downloaded path)\u001b[39;00m\n\u001b[1;32m--> 445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manual_dir \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_manual_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    446\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m path  \u001b[38;5;66;03m# Manually downloaded data\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m path \u001b[38;5;241m==\u001b[39m checksum_path:  \u001b[38;5;66;03m# Path already at final destination\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001b[0m, in \u001b[0;36mPath.is_relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\pathlib.py:679\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_segments(other, \u001b[38;5;241m*\u001b[39m_deprecated)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m walk_up:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001b[0m, in \u001b[0;36mPath.is_relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\pathlib.py:679\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_segments(other, \u001b[38;5;241m*\u001b[39m_deprecated)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m walk_up:\n",
      "    \u001b[1;31m[... skipping similar frames: Path.is_relative_to at line 78 (741 times), PurePath.relative_to at line 679 (740 times)]\u001b[0m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\pathlib.py:679\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_segments(other, \u001b[38;5;241m*\u001b[39m_deprecated)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[1;32m--> 679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_relative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    680\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    681\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m walk_up:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\abstract_path.py:78\u001b[0m, in \u001b[0;36mPath.is_relative_to\u001b[1;34m(self, *other)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return True if the path is relative to another path or False.\"\"\"\u001b[39;00m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\pathlib.py:677\u001b[0m, in \u001b[0;36mPurePath.relative_to\u001b[1;34m(self, other, walk_up, *_deprecated)\u001b[0m\n\u001b[0;32m    672\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msupport for supplying more than one positional argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    673\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pathlib.PurePath.relative_to() is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    674\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscheduled for removal in Python \u001b[39m\u001b[38;5;132;01m{remove}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    675\u001b[0m     warnings\u001b[38;5;241m.\u001b[39m_deprecated(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpathlib.PurePath.relative_to(*args)\u001b[39m\u001b[38;5;124m\"\u001b[39m, msg,\n\u001b[0;32m    676\u001b[0m                          remove\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m14\u001b[39m))\n\u001b[1;32m--> 677\u001b[0m other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_segments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_deprecated\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([other] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(other\u001b[38;5;241m.\u001b[39mparents)):\n\u001b[0;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_relative_to(path):\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\pathlib.py:385\u001b[0m, in \u001b[0;36mPurePath.with_segments\u001b[1;34m(self, *pathsegments)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwith_segments\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mpathsegments):\n\u001b[0;32m    381\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Construct a new path object from any number of path-like objects.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;124;03m    Subclasses may override this method to customize how new path objects\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;124;03m    are created from methods like `iterdir()`.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpathsegments\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:81\u001b[0m, in \u001b[0;36m_GPath.__new__\u001b[1;34m(cls, *parts)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[_P], \u001b[38;5;241m*\u001b[39mparts: PathLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _P:\n\u001b[1;32m---> 81\u001b[0m   full_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m full_path\u001b[38;5;241m.\u001b[39mstartswith(_URI_PREFIXES):\n\u001b[0;32m     83\u001b[0m     prefix, _ \u001b[38;5;241m=\u001b[39m full_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m'\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:81\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m: Type[_P], \u001b[38;5;241m*\u001b[39mparts: PathLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _P:\n\u001b[1;32m---> 81\u001b[0m   full_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parts)\n\u001b[0;32m     82\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m full_path\u001b[38;5;241m.\u001b[39mstartswith(_URI_PREFIXES):\n\u001b[0;32m     83\u001b[0m     prefix, _ \u001b[38;5;241m=\u001b[39m full_path\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m'\u001b[39m, maxsplit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:133\u001b[0m, in \u001b[0;36m_GPath.__fspath__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__fspath__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m--> 133\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path_str\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\etils\\epath\\gpath.py:130\u001b[0m, in \u001b[0;36m_GPath._path_str\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    128\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_PATH\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muri_scheme\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m://\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts[\u001b[38;5;241m2\u001b[39m:])\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_PATH\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparts\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m<frozen ntpath>:121\u001b[0m, in \u001b[0;36mjoin\u001b[1;34m(path, *paths)\u001b[0m\n",
      "\u001b[1;31mRecursionError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "ds_train = tfds.load(\"horses_or_humans\", split='train')\n",
    "df_train = tfds.as_dataframe(ds_train)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NzRjWOcJII9"
   },
   "source": [
    "Загрузим из обучающей выборки первое изображение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VbbDOs0_JII-"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hlfo2Qj-JII-"
   },
   "outputs": [],
   "source": [
    "img = Image.fromarray(df_train.iloc[0]['image'])\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmY0NLLWJII_"
   },
   "source": [
    "Изображение является цветным и использует три канала:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cldCij_2JII_"
   },
   "outputs": [],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKULnPgAJIJA"
   },
   "source": [
    "Чтобы упростить работу с изображением, перейдем к изображению с оттенками серого:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqoJVCycJIJA"
   },
   "outputs": [],
   "source": [
    "img = ImageOps.grayscale(img)\n",
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bq22T-itJIJD"
   },
   "source": [
    "Для визуализации будем использовать следующие функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ML5t9MTsJIJD"
   },
   "outputs": [],
   "source": [
    "def plot_image(img: np.array):\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap='gray');\n",
    "\n",
    "def plot_two_images(img1: np.array, img2: np.array):\n",
    "    _, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    ax[0].imshow(img1, cmap='gray')\n",
    "    ax[1].imshow(img2, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtUhoDoIJIJE"
   },
   "outputs": [],
   "source": [
    "plot_image(img=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHN23GjDJIJF"
   },
   "source": [
    "## Свертка изображения\n",
    "\n",
    "Свертка сводится к повторяющемуся матричному поэлементному умножению и суммированию, которое может быть легко реализовано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EReUTyetJIJG"
   },
   "source": [
    "### Фильтры для свертки\n",
    "\n",
    "Задача сверточного слоя — найти фильтры (ядра), которые лучше всего извлекают признаки из набора данных с изображениями.\n",
    "\n",
    "Рассмотрим следующие матрицы размерами 3x3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J94gnmGMJIJH"
   },
   "outputs": [],
   "source": [
    "sharpen = np.array([\n",
    "    [0, -1, 0],\n",
    "    [-1, 5, -1],\n",
    "    [0, -1, 0]\n",
    "])\n",
    "\n",
    "blur = np.array([\n",
    "    [0.0625, 0.125, 0.0625],\n",
    "    [0.125,  0.25,  0.125],\n",
    "    [0.0625, 0.125, 0.0625]\n",
    "])\n",
    "\n",
    "outline = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1,  8, -1],\n",
    "    [-1, -1, -1]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PsEO-QimJIJJ"
   },
   "source": [
    "## Реализация свертки\n",
    "\n",
    "Объявим вспомогательную функцию, которая будет вычислять размеры изображения.\n",
    "\n",
    "Например, при использовании фильтра 3x3 будем терять по одному пикселю с каждого края."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLfgupXaJIJK"
   },
   "outputs": [],
   "source": [
    "def calculate_target_size(img_size: int, kernel_size: int) -> int:\n",
    "    num_pixels = 0\n",
    "\n",
    "    for i in range(img_size):\n",
    "        added = i + kernel_size\n",
    "        if added <= img_size:\n",
    "            num_pixels += 1\n",
    "\n",
    "    return num_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GhWjObQkJIJL"
   },
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=300, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ipSKvmILJIJM"
   },
   "outputs": [],
   "source": [
    "calculate_target_size(img_size=300, kernel_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmH-VMOsJIJN"
   },
   "source": [
    "Свертка работает так:\n",
    "1. Извлекаем первую матрицу 3x3 из изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITn7drA_JIJN"
   },
   "outputs": [],
   "source": [
    "subset = np.array(img)[0:0+3, 0:0+3]\n",
    "subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OB85fkoKJIJO"
   },
   "source": [
    "2. Производим поэлементное умножение изображения на фильтр:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcGviJeUJIJP"
   },
   "outputs": [],
   "source": [
    "np.multiply(subset, sharpen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t45idmsZJIJP"
   },
   "source": [
    "3. Суммируем элементы матрицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IFV0JILWJIJQ"
   },
   "outputs": [],
   "source": [
    "np.sum(np.multiply(subset, sharpen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJGDAbfqJIJQ"
   },
   "source": [
    "Применим эту логику ко всей матрице. Нужно перебрать все допустимые строки и столбцы в изображении, а затем умножить на фильтр и просуммировать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rO-fbW1NJIJQ"
   },
   "outputs": [],
   "source": [
    "def convolve(img: np.array, kernel: np.array) -> np.array:\n",
    "    # Assuming a rectangular image\n",
    "    tgt_size = calculate_target_size(\n",
    "        img_size=img.shape[0],\n",
    "        kernel_size=kernel.shape[0]\n",
    "    )\n",
    "    # To simplify things\n",
    "    k = kernel.shape[0]\n",
    "\n",
    "    # 2D array of zeros\n",
    "    convolved_img = np.zeros(shape=(tgt_size, tgt_size))\n",
    "\n",
    "    # Iterate over the rows\n",
    "    for i in range(tgt_size):\n",
    "        # Iterate over the columns\n",
    "        for j in range(tgt_size):\n",
    "            # img[i, j] = individual pixel value\n",
    "            # Get the current matrix\n",
    "            mat = img[i:i+k, j:j+k]\n",
    "\n",
    "            # Apply the convolution - element-wise multiplication and summation of the result\n",
    "            # Store the result to i-th row and j-th column of our convolved_img array\n",
    "            convolved_img[i, j] = np.sum(np.multiply(mat, kernel))\n",
    "\n",
    "    return convolved_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4BIsELxCJIJR"
   },
   "source": [
    "Применим фильтр повышения резкости в первую очередь:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cbbfKPNnJIJR"
   },
   "outputs": [],
   "source": [
    "img_sharpened = convolve(img=np.array(img), kernel=sharpen)\n",
    "img_sharpened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2UeFEj_ZJIJR"
   },
   "source": [
    "Визуализируем исходное и полученное изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u84D24BKJIJS"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img,\n",
    "    img2=img_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPL0QnDnJIJS"
   },
   "source": [
    "Оттенки немного отличаются, так как значения в матрице `img_sharpened` не находятся в диапазоне от 0 до 255. Можно исправить это, заменив все отрицательные значения нулями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o9hXPx33JIJT"
   },
   "outputs": [],
   "source": [
    "def negative_to_zero(img: np.array) -> np.array:\n",
    "    img = img.copy()\n",
    "    img[img < 0] = 0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XTHMdTmJIJT"
   },
   "source": [
    "Снова выполним визуализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWnaGvjaJIJT"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img,\n",
    "    img2=negative_to_zero(img=img_sharpened)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uf_Vbf4dJIJU"
   },
   "source": [
    "Изображение определенно выглядит более четким.\n",
    "\n",
    "Теперь сделаем изображение более размытым:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKMUJ8pcJIJU"
   },
   "outputs": [],
   "source": [
    "img_blurred = convolve(img=np.array(img), kernel=blur)\n",
    "plot_two_images(\n",
    "    img1=img,\n",
    "    img2=img_blurred\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y97n2Wk8JIJU"
   },
   "source": [
    "Матрица фильтра размытия не имеет отрицательных значений, поэтому оттенки идентичны.\n",
    "\n",
    "Наконец, давайте применим фильтр контура:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwchP8bBJIJV"
   },
   "outputs": [],
   "source": [
    "img_outlined = convolve(img=np.array(img), kernel=outline)\n",
    "plot_two_images(\n",
    "    img1=img,\n",
    "    img2=img_outlined\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7koDfunJIJV"
   },
   "source": [
    "Этот фильтр также требует корректировки оттенков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwPXEcgqJIJV"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img,\n",
    "    img2=negative_to_zero(img=img_outlined)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USk4BpWAJIJW"
   },
   "source": [
    "Все изображения после свертки имеют размеры 298x298."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nWEKc0hcJIJW"
   },
   "outputs": [],
   "source": [
    "np.array(img_sharpened).shape, np.array(img_blurred).shape, np.array(img_outlined).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSiGu8-MJIJW"
   },
   "source": [
    "### Реализация свертки с заполнением отступа (padding)\n",
    "\n",
    "Слой TensorFlow `Conv2D` позволяет указывать для параметра `padding` значения `valid` или `same`.\n",
    "\n",
    "Первый вариант (по умолчанию) означает, что к изображениям не добавляется отступ.\n",
    "Второй вариант добавляет отступы в зависимости от размера фильтра (ядра), поэтому исходное и свернутое изображения имеют одинаковую форму. Отступы - это, по сути, просто черная рамка вокруг изображения с добавленными нулями. Нули не влияют на вычисления, так как операция свертки умножает элементы изображения на элементы фильтра. Любой множитель, умноженный на ноль, дает в результате ноль.\n",
    "\n",
    "Объявим вспомогательную функцию, которая вычисляет, насколько «толстую» границу нам нужно добавить к изображению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fw41q_PjJIJX"
   },
   "outputs": [],
   "source": [
    "def get_padding_width_per_side(kernel_size: int) -> int:\n",
    "    return kernel_size // 2 # целочисленное деление"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bt5OfNQBJIJX"
   },
   "outputs": [],
   "source": [
    "pad_3x3 = get_padding_width_per_side(kernel_size=3)\n",
    "pad_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GiLD-xsJIJX"
   },
   "outputs": [],
   "source": [
    "pad_5x5 = get_padding_width_per_side(kernel_size=5)\n",
    "pad_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwzrcQSGJIJY"
   },
   "source": [
    "Объявим еще одну вспомогательную функцию, задача которой добавить отступ к изображению. Функция объявляет матрицу нулей формы `(image.shape + padding * 2)`. Отступы умножаются на 2, потому что они нужны со всех сторон. Затем мы индексируем матрицу, чтобы проигнорировать заполнение, и заменяем нули фактическими значениями изображения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FR0xGr94JIJY"
   },
   "outputs": [],
   "source": [
    "def add_padding_to_image(img: np.array, padding_width: int) -> np.array:\n",
    "    # Array of zeros of shape (img + padding_width)\n",
    "    img_with_padding = np.zeros(shape=(\n",
    "        img.shape[0] + padding_width * 2,  # Multiply with two because we need padding on all sides\n",
    "        img.shape[1] + padding_width * 2\n",
    "    ))\n",
    "\n",
    "    # Change the inner elements\n",
    "    # For example, if img.shape = (224, 224), and img_with_padding.shape = (226, 226)\n",
    "    # keep the pixel wide padding on all sides, but change the other values to be the same as img\n",
    "    img_with_padding[padding_width:-padding_width, padding_width:-padding_width] = img\n",
    "\n",
    "    return img_with_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LIz6XMO7JIJZ"
   },
   "outputs": [],
   "source": [
    "img_with_padding_3x3 = add_padding_to_image(\n",
    "    img=np.array(img),\n",
    "    padding_width=pad_3x3\n",
    ")\n",
    "\n",
    "print(img_with_padding_3x3.shape)\n",
    "plot_image(img_with_padding_3x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tx7o5MuJJIJZ"
   },
   "outputs": [],
   "source": [
    "img_with_padding_3x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UZKWU3AjJIJa"
   },
   "outputs": [],
   "source": [
    "img_with_padding_5x5 = add_padding_to_image(\n",
    "    img=np.array(img),\n",
    "    padding_width=pad_5x5\n",
    ")\n",
    "\n",
    "print(img_with_padding_5x5.shape)\n",
    "plot_image(img_with_padding_5x5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4yT6afNJIJa"
   },
   "outputs": [],
   "source": [
    "img_with_padding_5x5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVo9eBDwJIJb"
   },
   "source": [
    "Применим операцию свертки к нашему изображению 302x302 (граница шириной 1 пиксель):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wq4nw2hFJIJb"
   },
   "outputs": [],
   "source": [
    "img_padded_3x3_sharpened = convolve(img=img_with_padding_3x3,\n",
    "                                    kernel=sharpen)\n",
    "img_padded_3x3_sharpened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRanL9TmJIJc"
   },
   "source": [
    "В результате получается изображение размером 300x300, такое же, как и исходное.\n",
    "Построим оба изображения рядом, чтобы проверить:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "byf74xt3JIJc"
   },
   "outputs": [],
   "source": [
    "plot_two_images(\n",
    "    img1=img,\n",
    "    img2=img_padded_3x3_sharpened\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V94fiXhPJIJd"
   },
   "source": [
    "## Пулинг (pooling)\n",
    "\n",
    "Пулинг сводится к разделению 2D-массива на более мелкие фрагменты, что может быть легко реализовано.\n",
    "\n",
    "Объявим небольшой 2D-массив, который будет представлять выходные данные сверточного слоя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2UXe4DqnJIJd"
   },
   "outputs": [],
   "source": [
    "conv_output = np.array([\n",
    "    [10, 12,  8,  7],\n",
    "    [ 4, 11,  5,  9],\n",
    "    [18, 13,  7,  7],\n",
    "    [ 3, 15,  2,  2]\n",
    "])\n",
    "conv_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdkS6OrGJIJe"
   },
   "source": [
    "Для пулинга нужно выбрать значения для двух гиперпараметров:\n",
    "* `pool_size` — размер области, скользящей по изображению\n",
    "* `stride` - количество пикселей, на которое область перемещается по изображению\n",
    "\n",
    "Общепринятые размеры: 2 x 2 для размера пула (`pool_size`) и 2 для шага (`stride`).\n",
    "Выбор этих значений уменьшит размер результата свертки вдвое.\n",
    "Размер пула 2 x 2 и шаг 1 уменьшат размер изображения на один пиксель, что не имеет особого смысла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4wRsB-HJIJe"
   },
   "outputs": [],
   "source": [
    "# Define paramters\n",
    "pool_size = 2\n",
    "stride = 2\n",
    "\n",
    "# For all rows with the step size of 2 (row 0 and row 2)\n",
    "for i in np.arange(conv_output.shape[0], step=stride):\n",
    "    # For all columns with the step size of 2 (column 0 and column 2)\n",
    "    for j in np.arange(conv_output.shape[0], step=stride):\n",
    "        # Get a single pool\n",
    "        mat = conv_output[i:i+pool_size, j:j+pool_size]\n",
    "\n",
    "        # Ensure that the shape of the matrix is 2x2 (pool size)\n",
    "        if mat.shape == (pool_size, pool_size):\n",
    "            # Print it\n",
    "            print(mat)\n",
    "    # Print a new line when the code reaches the end of a single row block\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6QK1hlrJIJe"
   },
   "source": [
    "Оформим все это в виде функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UME3oErBJIJf"
   },
   "outputs": [],
   "source": [
    "def get_pools(img: np.array, pool_size: int, stride: int) -> np.array:\n",
    "    # To store individual pools\n",
    "    pools = []\n",
    "\n",
    "    # Iterate over all row blocks (single block has `stride` rows)\n",
    "    for i in np.arange(img.shape[0], step=stride):\n",
    "        # Iterate over all column blocks (single block has `stride` columns)\n",
    "        for j in np.arange(img.shape[0], step=stride):\n",
    "\n",
    "            # Extract the current pool\n",
    "            mat = img[i:i+pool_size, j:j+pool_size]\n",
    "\n",
    "            # Make sure it's rectangular - has the shape identical to the pool size\n",
    "            if mat.shape == (pool_size, pool_size):\n",
    "                # Append to the list of pools\n",
    "                pools.append(mat)\n",
    "\n",
    "    # Return all pools as a Numpy array\n",
    "    return np.array(pools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "outcQ46GJIJf"
   },
   "outputs": [],
   "source": [
    "test_pools = get_pools(img=conv_output, pool_size=2, stride=2)\n",
    "test_pools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_h-4JHpJIJf"
   },
   "source": [
    "### Макс-пулинг (MaxPooling)\n",
    "\n",
    "`MaxPooling` — самый распространенный тип пулинга, сохраняющий только самое большое значение из одного пула.\n",
    "\n",
    "**Логика макс-пулинга**\n",
    "1. Получить общее количество пулов - длину матрицы `pools` (или `shape[0]`)\n",
    "2. Рассчитать целевую форму - размер изображения после выполнения операции объединения.\n",
    "     - Рассчитывается как: квадратный корень из числа пулов, представленных как целое число.\n",
    "     - Если `num_pools` равно 16, то нужна матрица 4x4 (sqrt(16) = 4)\n",
    "3. Перебрать все пулы и вычислить максимальное значение — добавить максимальное значение в список результатов.\n",
    "4. Вернуть результат в виде массива Numpy, преобразованного в целевую форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ND3KcOFHJIJg"
   },
   "outputs": [],
   "source": [
    "def max_pooling(pools: np.array) -> np.array:\n",
    "    # Total number of pools\n",
    "    num_pools = pools.shape[0]\n",
    "    # Shape of the matrix after pooling - Square root of the number of pools\n",
    "    # Cast it to int, as Numpy will return it as float\n",
    "    # For example -> np.sqrt(16) = 4.0 -> int(4.0) = 4\n",
    "    tgt_shape = (int(np.sqrt(num_pools)), int(np.sqrt(num_pools)))\n",
    "    # To store the max values\n",
    "    pooled = []\n",
    "\n",
    "    # Iterate over all pools\n",
    "    for pool in pools:\n",
    "        # Append the max value only\n",
    "        pooled.append(np.max(pool))\n",
    "\n",
    "    # Reshape to target shape\n",
    "    return np.array(pooled).reshape(tgt_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p2sAjJTFJIJg"
   },
   "outputs": [],
   "source": [
    "max_pooling(pools=test_pools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76tCjqy4JIJh"
   },
   "source": [
    "### Пулинг на реальном изображении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmM8FQHxJIJh"
   },
   "outputs": [],
   "source": [
    "np.array(img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6IBXeVOJIJh"
   },
   "outputs": [],
   "source": [
    "img_pools = get_pools(img=np.array(img), pool_size=2, stride=2)\n",
    "img_pools.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1DRLZ8FlJIJi"
   },
   "outputs": [],
   "source": [
    "max_pooled = max_pooling(pools=img_pools)\n",
    "max_pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhlh7BX-JIJi"
   },
   "outputs": [],
   "source": [
    "plot_two_images(img1=img, img2=max_pooled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee5IyilXJIJi"
   },
   "source": [
    "Изображение справа отображается в том же размере, что и изображение слева, несмотря на то, что оно меньше — проверьте значения по осям X и Y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnzja39-JIJj"
   },
   "source": [
    "### Пулинг при помощи TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ba_Zb59mJIJj"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrOvjN4IJIJj"
   },
   "source": [
    "Эту модель не нужно обучать. Но нужно изменить форму изображения, приведя ее к формату:\n",
    "* (batch size, width, height, number of color channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RspB91FdJIJk"
   },
   "outputs": [],
   "source": [
    "img_arr = np.array(img).reshape(1, 300, 300, 1)\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tl_YSsPYJIJk"
   },
   "source": [
    "Можно воспользоваться методом `predict()`, чтобы применить пулинг. Будет возвращен тензор размеров 1x150x150x1, поэтому нужно изменить его форму на 150x150:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYCuzhaKJIJk"
   },
   "outputs": [],
   "source": [
    "output = model.predict(img_arr).reshape(150, 150)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qp1zmF2LJIJl"
   },
   "source": [
    "При помощи функции `array_equal()` из Numpy можно проверить, что два массива равны:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PICA3rUJIJl"
   },
   "outputs": [],
   "source": [
    "np.array_equal(max_pooled, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFZvnVhNJIJm"
   },
   "source": [
    "## Набор \"лошади или люди\" (horses_or_humans)\n",
    "\n",
    "Вернемся к набору данных `horses_or_humans` и создадим обучающие и тестовые наборы данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eXaB6Od9hQMH"
   },
   "outputs": [],
   "source": [
    "ds = tfds.load(\"horses_or_humans\", split=['train','test'])\n",
    "df_train = tfds.as_dataframe(ds[0])\n",
    "df_test  = tfds.as_dataframe(ds[1])\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zMPw3kmyJIJo"
   },
   "outputs": [],
   "source": [
    "df_train.iloc[0]['image'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpshtWpyJIJp"
   },
   "outputs": [],
   "source": [
    "train_labels = df_train['label'].to_numpy(dtype=np.float32)\n",
    "test_labels = df_test['label'].to_numpy(dtype=np.float32)\n",
    "train_labels.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9CrdoxhJIJp"
   },
   "outputs": [],
   "source": [
    "train_images = np.zeros(shape=(df_train.shape[0],300,300,3), dtype=np.float32)\n",
    "test_images  = np.zeros(shape=(df_test.shape[0],300,300,3), dtype=np.float32)\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDyW3nkyJIJq"
   },
   "outputs": [],
   "source": [
    "for idx in range(train_labels.shape[0]):\n",
    "    train_images[idx,:,:,:] = \\\n",
    "        np.array(Image.fromarray(df_train.iloc[idx]['image']))\n",
    "\n",
    "for idx in range(test_labels.shape[0]):\n",
    "    test_images[idx,:,:,:] = \\\n",
    "        np.array(Image.fromarray(df_test.iloc[idx]['image']))\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vFjL0jdYk2R9"
   },
   "outputs": [],
   "source": [
    "train_images /= 255\n",
    "test_images  /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkkXj3s2JIJs"
   },
   "source": [
    "## Визуализация изображений\n",
    "\n",
    "Всегда рекомендуется визуализировать некоторые изображения при работе с наборами данных изображений.\n",
    "Функция ниже отображает случайное подмножество из 10 изображений набора данных в сетке из 2 строк и 5 столбцов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uwuPYpkWJIJs"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def plot_random_sample(images):\n",
    "    n = 10\n",
    "    imgs = random.sample(list(images), n)\n",
    "\n",
    "    num_row = 2\n",
    "    num_col = 5\n",
    "\n",
    "    fig, axes = plt.subplots(num_row, num_col, figsize=(3.5 * num_col, 3 * num_row))\n",
    "    # For every image\n",
    "    for i in range(num_row * num_col):\n",
    "        # Read the image\n",
    "        img = imgs[i]\n",
    "        # Display the image\n",
    "        ax = axes[i // num_col, i % num_col]\n",
    "        ax.imshow(img)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZxCxk0MaOoB"
   },
   "outputs": [],
   "source": [
    "plt.imshow(test_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6yh5qRTUJIJs"
   },
   "outputs": [],
   "source": [
    "plot_random_sample(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNiNNY9WJIJt"
   },
   "source": [
    "## Обучение нейронной сети MLP\n",
    "\n",
    "В качестве функции потерь используется бинарная кросс-энтропия."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eGB-WPzIJIJt"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_1 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(300, 300, 3)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_1.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8EztFJFJIJu"
   },
   "source": [
    "## Показатели качества модели\n",
    "\n",
    "Визуализируем потери на обучающей и тестовой выборках и долю верных ответов (accuracy) на обучающей и тестовой выборках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FU1xnBOTJIJu"
   },
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams['figure.figsize'] = (18, 8)\n",
    "rcParams['axes.spines.top'] = False\n",
    "rcParams['axes.spines.right'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FCkv3xrbJIJu"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 51), history_1.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 51), history_1.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5w2s209yJIJu"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 51), history_1.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(np.arange(1, 51), history_1.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33GAqJX6JIJv"
   },
   "source": [
    "Показатели качества модели весьма средние."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "16oHabR2JIJv"
   },
   "source": [
    "## Обучение сверточной модели\n",
    "\n",
    "Как и в случае с обычных нейросетей (с плотными слоями), сверточные нейронные сети требуют экспериментов.\n",
    "Заранее не известно, сколько сверточных слоев понадобится, какое идеальное количество фильтров для каждого слоя и каков оптимальный размер ядра.\n",
    "\n",
    "За сверточными слоями обычно следует слой пулинга, чтобы уменьшить размер изображения.\n",
    "После сверточных слоев  нужно обязательно добавить слой `Flatten`.\n",
    "Далее следуют плотные слои.\n",
    "\n",
    "Следует правильно выбрать выходной слой и функцию потерь.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uKXHfss9JIJv"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3),\n",
    "                           input_shape=(300, 300, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3),\n",
    "                           activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_2.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy,\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy(name='accuracy')]\n",
    ")\n",
    "\n",
    "history_2 = model_2.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    validation_data=(test_images, test_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ak43qebeJIJv"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 16), history_2.history['loss'], label='Training Loss')\n",
    "plt.plot(np.arange(1, 16), history_2.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs. Validation Loss', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zVsOfQykJIJw"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.arange(1, 16), history_2.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(np.arange(1, 16), history_2.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs. Validation Accuracy', size=20)\n",
    "plt.xlabel('Epoch', size=14)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvrOTmXEBUVS"
   },
   "source": [
    "#### Задание (10 баллов)\n",
    "\n",
    "Для закрепленного за Вами варианта лабораторной работы:\n",
    "\n",
    "1. Загрузите заданный в индивидуальном задании набор данных с изображениями из Tensorflow Datasets с разбиением на обучающую и тестовую выборки.\n",
    "\n",
    "2. Визуализируйте несколько изображений, отобранных случайным образом из обучающей выборки.\n",
    "\n",
    "3. Оставьте в наборе изображения двух классов, указанных в индивидуальном задании первыми. Обучите нейронные сети MLP и CNN задаче бинарной классификации изображений (требования к архитектуре сетей указаны в индивидуальном задании). Отследите обучение нейронных сетей и укажите, на сколько процентов снизились в результате обучения потери по отношению к потерям на первой эпохе обучения. Оцените результаты обучения нейронных сетей (варианты: нейронная сеть обучилась, недообучилась, переобучилась).   \n",
    "\n",
    "4. Постройте кривые обучения нейронных сетей бинарной классификации для показателей потерь и доли верных ответов в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду.\n",
    "\n",
    "5. Сравните качество бинарной классификации нейронными сетями при помощи показателя качества, указанного в индивидуальном задании.\n",
    "\n",
    "6. Визуализируйте ROC-кривые для построенных классификаторов на одном рисунке (с легендой) и вычислите площади под ROC-кривыми.\n",
    "\n",
    "7. Оставьте в наборе изображения трех классов, указанных в индивидуальном задании. Обучите нейронные сети MLP и CNN задаче многоклассовой классификации изображений (требования к архитектуре сетей указаны в индивидуальном задании).\n",
    "\n",
    "8. Сравните качество многоклассовой классификации нейронными сетями при помощи показателя качества, указанного в индивидуальном задании.\n",
    "\n",
    "9. Постройте кривые обучения нейронных сетей многоклассовой классификации для показателей ошибки и доли верных ответов в зависимости от эпохи обучения, подписывая оси и рисунок и создавая легенду.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6ul5EHxsDZgp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
