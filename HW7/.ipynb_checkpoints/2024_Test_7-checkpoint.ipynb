{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yAHyZgUGrjrS"
   },
   "source": [
    "# Методы машинного обучения – Контрольная работа №7\n",
    "\n",
    "# Автокодировщики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoofZNYbrnyI"
   },
   "source": [
    "Импортируем нужные на этой лабораторной работе библиотеки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUNNih8SlLaO"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EFOxMEhus07"
   },
   "source": [
    "## Наборы данных MNIST и FASHION MNIST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9TWvBlH5cqm"
   },
   "source": [
    "Используем в материалах этой лабораторной работы два набора данных:\n",
    "\n",
    "- [MNIST Dataset](http://yann.lecun.com/exdb/mnist/)\n",
    "- [Fashion MNIST @ Zalando](https://research.zalando.com/welcome/mission/research-projects/fashion-mnist/)\n",
    "\n",
    "Эти наборы легко импортируются при помощи `keras` ([```tensorflow.keras.datasets```](https://www.tensorflow.org/api_docs/python/tf/keras/datasets))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-IQf1yl8uyQ-",
    "outputId": "d9462d64-f06d-4877-f0f7-409129dbc89b"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(mnist_x_train, mnist_y_train), (mnist_x_test, mnist_y_test) = \\\n",
    "    mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8TfQEXmvALJ",
    "outputId": "a3cce647-0e5a-41e3-90c5-101244c86c47"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(fashion_x_train,fashion_y_train), (fashion_x_test,fashion_y_test) = \\\n",
    "    fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Логарифмическое правдоподобие профиля\n",
    "\n",
    "Определим размерность латентного пространства при помощи метода PCA и правдоподобия профиля. Для вычисления логарифмического правдоподобия профиля будем использовать следующую функцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import multivariate_normal\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", RuntimeWarning)  # for some NaN values\n",
    "\n",
    "# Function to calculate log likelihood of PCA from eigenvalues\n",
    "\n",
    "def log_likelihood(evals):\n",
    "\n",
    "    Lmax = len(evals)\n",
    "    ll = np.arange(0.0, Lmax)\n",
    "\n",
    "    for L in range(Lmax):\n",
    "\n",
    "        group1 = evals[0 : L + 1]  # Divide Eigenvalues in two groups\n",
    "        group2 = evals[L + 1 : Lmax]\n",
    "\n",
    "        mu1 = np.mean(group1)\n",
    "        mu2 = np.mean(group2)\n",
    "\n",
    "        sigma = (np.sum((group1 - mu1) ** 2) + np.sum((group2 - mu2) ** 2)) / Lmax\n",
    "\n",
    "        ll_group1 = np.sum(multivariate_normal.logpdf(group1, mu1, sigma))\n",
    "        ll_group2 = np.sum(multivariate_normal.logpdf(group2, mu2, sigma))\n",
    "\n",
    "        ll[L] = ll_group1 + ll_group2 \n",
    "\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем небольшую часть набора `MNIST` для цифры 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_x_train3 = mnist_x_train[mnist_y_train == 3]  # select images of digit '3'\n",
    "\n",
    "n_images = 1000\n",
    "train_images = mnist_x_train3[0:n_images, :, :]\n",
    "n_samples, n_rows, n_cols = mnist_x_train3.shape\n",
    "X = np.reshape(mnist_x_train3, (n_samples, n_rows * n_cols))\n",
    "\n",
    "X_train = X[0 : int(n_images / 2), :]  # 500 images in train set\n",
    "X_test = X[int(n_images / 2) :, :]  # 500 images in test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим ошибку реконструкции для различного числа главных компонент: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error on MNIST vs number of latent dimensions used by PCA\n",
    "\n",
    "X_rank = np.linalg.matrix_rank(X_train)\n",
    "K_linspace = np.linspace(1, 0.75 * X_rank, 10, dtype=int)\n",
    "Ks = np.unique(np.append([1, 5, 10, 20], K_linspace))\n",
    "\n",
    "RMSE_train = np.arange(len(Ks))\n",
    "RMSE_test = np.arange(len(Ks))\n",
    "\n",
    "for index, K in enumerate(Ks):\n",
    "    pca = PCA(n_components=K)\n",
    "\n",
    "    Xtrain_transformed = pca.fit_transform(X_train)\n",
    "    Xtrain_proj = pca.inverse_transform(Xtrain_transformed)\n",
    "    RMSE_train[index] = mean_squared_error(X_train, Xtrain_proj, squared=False)\n",
    "\n",
    "    Xtest_transformed = pca.transform(X_test)\n",
    "    Xtest_proj = pca.inverse_transform(Xtest_transformed)\n",
    "    RMSE_test[index] = mean_squared_error(X_test, Xtest_proj, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим логарифмическое правдоподобие профиля для различного числа главных компонент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile log likelihood for PCA\n",
    "\n",
    "n_samples, n_features = X_train.shape\n",
    "Kmax = min(n_samples, n_features)\n",
    "\n",
    "pca = PCA(n_components=Kmax)\n",
    "X_transformed = pca.fit_transform(X_train)\n",
    "evals = pca.explained_variance_  # eigenvalues in descending order\n",
    "\n",
    "ll = log_likelihood(evals)\n",
    "\n",
    "# Fraction of variance explained\n",
    "\n",
    "fraction_var = np.cumsum(evals[0:50] / np.sum(evals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь выполним визуализацию ошибки реконструкции и логарифмического правдоподобия профиля для различного числа главных компонент:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "xs = Ks\n",
    "ys = RMSE_train\n",
    "plt.title(\"Ошибка в зависимости от числа главных компонент\")\n",
    "plt.xlabel(\"Число главных компонент\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "ax.plot(xs, ys, marker=\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xs = np.arange(1, 51)\n",
    "ys = ll[0:50]\n",
    "plt.xlabel(\"Число главных компонент\")\n",
    "plt.ylabel(\"Логарифмическое правдоподобие профиля\")\n",
    "\n",
    "ax.plot(xs, ys, marker=\"o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IUn1Qxoa6LBW"
   },
   "source": [
    "### Подготовка наборов данных для глубокого обучения\n",
    "\n",
    "Как обычно, выполним типичную нормализацию наборов данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MX96nM1u2Z0"
   },
   "outputs": [],
   "source": [
    "mnist_x_train = mnist_x_train.astype('float32') / 255.\n",
    "mnist_x_test  = mnist_x_test.astype('float32') / 255.\n",
    "\n",
    "fashion_x_train = fashion_x_train.astype('float32') / 255.\n",
    "fashion_x_test  = fashion_x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим варианты наборов данных для обучения сетей MLP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_x_train.shape, mnist_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MX96nM1u2Z0"
   },
   "outputs": [],
   "source": [
    "mnist_x_trainMLP = mnist_x_train.reshape(\n",
    "    (len(mnist_x_train), np.prod(mnist_x_train.shape[1:])))\n",
    "mnist_x_testMLP  = mnist_x_test.reshape(\n",
    "    (len(mnist_x_test), np.prod(mnist_x_test.shape[1:])))\n",
    "mnist_x_trainMLP.shape, mnist_x_testMLP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_x_train.shape, fashion_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lw3IFaPeu_3s"
   },
   "outputs": [],
   "source": [
    "fashion_x_trainMLP = fashion_x_train.reshape(\n",
    "    (len(fashion_x_train), np.prod(fashion_x_train.shape[1:])))\n",
    "fashion_x_testMLP  = fashion_x_test.reshape(\n",
    "    (len(fashion_x_test), np.prod(fashion_x_test.shape[1:])))\n",
    "fashion_x_trainMLP.shape, fashion_x_testMLP.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gsxM-4FYunrK"
   },
   "source": [
    "## Функция для создания автокодировщиков MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjqQlYFY6dEH"
   },
   "source": [
    "Автокодировщик состоит из двух частей: кодировщика (_encoder_) и декодера (_decoder_). Функция ```create_autoencoders()``` возвращает следующие объекты как отдельные модели:\n",
    "\n",
    "- кодировщик \n",
    "- декодер\n",
    "- полную модель, включающую кодировщик и декодер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9e3_MUYyuHp-"
   },
   "outputs": [],
   "source": [
    "def create_autoencoders (feature_layer_dim = 16):\n",
    "    input_img = Input(shape = (784,), name = 'Input_Layer')\n",
    "    # Слой encoded имеет размерность, равную feature_layer_dim \n",
    "    # и содержит закодированные входные данные \n",
    "    encoded = Dense(feature_layer_dim, activation = 'relu', \n",
    "                    name = 'Encoded_Features')(input_img)\n",
    "    decoded = Dense(784, activation = 'sigmoid', \n",
    "                    name = 'Decoded_Input')(encoded)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    encoder = Model(input_img, encoded)\n",
    "\n",
    "    encoded_input = Input(shape = (feature_layer_dim,))\n",
    "    decoder = autoencoder.layers[-1]\n",
    "    decoder = Model(encoded_input, decoder(encoded_input))\n",
    "\n",
    "    return autoencoder, encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6juVqpJvSQg"
   },
   "source": [
    "## Автокодировщик со слоями с $(784,16,784)$ нейронами\n",
    "\n",
    "Начнем с автокодировщика, имеющего слои с размерностями $(784, 16, 784)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5BaDqnbuY-I"
   },
   "outputs": [],
   "source": [
    "autoencoder16, encoder16, decoder16 = create_autoencoders(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "A157gXaewJI2",
    "outputId": "c2eee2ee-b7b8-4c2a-c34f-dea8b7fbbbb8"
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(autoencoder16, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9jNv0UMqwvJ9"
   },
   "source": [
    "Теперь нужно скомпилировать модель и обучить ее на данных. Для работы с автоэнкодерами достаточно простой модели **создать** $\\rightarrow$ **compile** $\\rightarrow$ **fit**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFv4sGg4mBkB"
   },
   "outputs": [],
   "source": [
    "autoencoder16.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxaS4XlLmLI7"
   },
   "outputs": [],
   "source": [
    "history = autoencoder16.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testMLP, mnist_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZaRLBur6mM2Y"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder16.predict(mnist_x_testMLP)\n",
    "decoded_imgs = decoder16.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFwBP1CdKWLi"
   },
   "source": [
    "### Относительно сжатия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1V3Z9_X-FPY"
   },
   "source": [
    "Поскольку мы сохранили и кодировщик, и декодер, мы можем создать закодированную версию изображений. Обратите внимание, что тип данных изображений — ```float32```. Каждый объект ```float32``` требует 4 байта. Исходные данные в ```mnist_x_test``` имеют вид ```(10000,784)```. Это означает, что пространство, необходимое для хранения этого массива, равно\n",
    "\n",
    "$$\n",
    "10000 \\textrm{ изображений} \\times 784 \\textrm{ пикселей}\\times 4 \\textrm{ байт} = 29 \\textrm{ Мб}\n",
    "$$\n",
    "\n",
    "Закодированные изображения требуют гораздо меньше места. На самом деле необходимый размер\n",
    "\n",
    "$$\n",
    "10000 \\textrm{ изображений}\\times 16 \\textrm{ скрытых признаков}\\times 4 \\textrm{ байт} = 625 \\textrm{ Кб}\n",
    "$$\n",
    "\n",
    "поэтому, если мы примем потерю качества в сжатых данных, мы получим невероятную степень сжатия около $46$. Эти размеры легко проверить, сохранив данные в файле и проверив размер файла. Обратите внимание, что размер файла будет больше, так как есть некоторая дополнительная информация, которую необходимо сохранить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "E1lYjk66-ZQs",
    "outputId": "e6bcacdf-0a12-4831-9ccf-9be6b5806df8"
   },
   "outputs": [],
   "source": [
    "np.save('temp_orig', mnist_x_testMLP)\n",
    "! ls -al temp_orig*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rjRKH8t1NBBP",
    "outputId": "94ab8ace-59e7-4d78-a32f-ee8bbfa15ed9"
   },
   "outputs": [],
   "source": [
    "np.save('temp_encoded', encoded_imgs)\n",
    "! ls -al temp_encoded*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xZ83T02HNG23"
   },
   "source": [
    "## Анализ реконструированных изображений\n",
    "\n",
    "Рассмотрим эффект от сжатия входных изображений. Наличие всего 16 нейронов в среднем слое дает следующий результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def image_show(orig_imgs, dec_imgs, fname=None):\n",
    "    n = 10  # кол-во изображений\n",
    "    fig = plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # исходные изображения\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(orig_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # реконструированные изображения\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(dec_imgs[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if fname:\n",
    "        fig.savefig(fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(mnist_x_testMLP, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7O6b2A0tP8j"
   },
   "source": [
    "## Автокодировщик со слоями с $(784,64,784)$ нейронами\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NFpLzQ0MtTkH"
   },
   "outputs": [],
   "source": [
    "autoencoder64, encoder64, decoder64 = create_autoencoders(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cusA73eRtWgW"
   },
   "outputs": [],
   "source": [
    "autoencoder64.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "zxSZA8tdtYRj",
    "outputId": "3e0bcb2d-a3b7-4f2f-ca4a-4262b3279e62"
   },
   "outputs": [],
   "source": [
    "autoencoder64.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testMLP, mnist_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SzN50nAoteN8"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder64.predict(mnist_x_testMLP)\n",
    "decoded_imgs = decoder64.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(mnist_x_testMLP, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ow0kHnTzupz"
   },
   "source": [
    "## Автокодировщик со слоями с $(784,8,784)$ нейронами\n",
    "\n",
    "При уменьшении количества нейронов в среднем слое качество реконструкции существенно падает:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "rwGSERoswp7Y",
    "outputId": "f1925cd9-1377-4cc7-a903-721a695c0fea"
   },
   "outputs": [],
   "source": [
    "autoencoder8, encoder8, decoder8 = create_autoencoders(8)\n",
    "autoencoder8.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder8.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testMLP, mnist_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLglZqluwxX3"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder8.predict(mnist_x_testMLP)\n",
    "decoded_imgs = decoder8.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(mnist_x_testMLP, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавление ограничения разреженности\n",
    "\n",
    "Еще один способ ограничить компактность представлений — добавить ограничение разреженности на активность скрытого представления, чтобы «срабатывало» меньшее количество нейронов. В Keras это можно сделать, добавив параметр `activity_regularizer` в плотный слой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import regularizers\n",
    "\n",
    "encoding_dim = 16\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "\n",
    "# плотный слой с регуляризатором активности L1 \n",
    "encoded = Dense(encoding_dim, activation='relu',\n",
    "    activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
    "\n",
    "decoded = Dense(784, activation='sigmoid')(encoded)\n",
    "\n",
    "autoencoderL1 = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoderL1.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoderL1.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testMLP, mnist_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoderL1.predict(mnist_x_testMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(mnist_x_testMLP, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Глубокий автокодировщик MLP\n",
    "\n",
    "Вместо одного слоя в кодировщике и декодере можно использовать несколько слоев:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dim = 16\n",
    "\n",
    "input_img = Input(shape=(784,))\n",
    "encoded = Dense(128, activation='relu')(input_img)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(128, activation='relu')(decoded)\n",
    "decoded = Dense(784, activation='sigmoid')(decoded)\n",
    "autoencoderD = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(autoencoderD, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoderD.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoderD.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testMLP, mnist_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сверточный автокодировщик\n",
    "\n",
    "Поскольку входными данными являются изображения, имеет смысл использовать сверточные нейронные сети в качестве кодировщиков и декодеров. На практике автокодировщики, применяемые к изображениям, всегда являются сверточными автокодировщиками — они работают намного лучше.\n",
    "\n",
    "Кодировщик будет состоять из стека слоев `Conv2D` и `MaxPooling2D` (максимальный пул используется для пространственной понижающей дискретизации), а декодер будет состоять из стека слоев `Conv2D` и `UpSampling2D`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,UpSampling2D\n",
    "\n",
    "input_img = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(16, (3,3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2,2), padding='same')(x)\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2,2), padding='same')(x)\n",
    "\n",
    "# Здесь представление (4, 4, 8) т.е. 128-мерное\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoderCNN = Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoderCNN.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_x_train.shape, mnist_x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8MX96nM1u2Z0"
   },
   "outputs": [],
   "source": [
    "mnist_x_trainCNN = mnist_x_train.reshape(\n",
    "    (len(mnist_x_train), 28, 28, 1))\n",
    "mnist_x_testCNN  = mnist_x_test.reshape(\n",
    "    (len(mnist_x_test), 28, 28, 1))\n",
    "mnist_x_trainCNN.shape, mnist_x_testCNN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoderCNN.fit(mnist_x_trainCNN, mnist_x_trainCNN,\n",
    "                epochs=5,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testCNN, mnist_x_testCNN),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(autoencoderCNN, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoderCNN.predict(mnist_x_testCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(mnist_x_testCNN, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2fD0-hMwzZT1"
   },
   "source": [
    "## Классификация по латентным признакам\n",
    "\n",
    "Проверим, как можно использовать скрытые (латентные) признаки или, другими словами, выходные данные среднего слоя, чтобы выполнить классификацию объектов. Что происходит с точностью и производительностью алгоритмов? Проверим несколько примеров.\n",
    "\n",
    "### Алгоритм kNN (метод ближайших соседей)\n",
    "\n",
    "Первым протестируем алгоритм kNN из библиотеки ```sklearn```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Hu9WJ_b4CjW"
   },
   "outputs": [],
   "source": [
    "encoded_train_imgs = encoder8.predict(mnist_x_trainMLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL98uuEV2dqg"
   },
   "source": [
    "Обратите внимание, что переменная ```encoded_train_imgs``` имеет только 8 признаков (последний обученный нами автокодировщик имел только 8 нейронов в среднем слое). В исходном наборе данных было 784 признаков (оттенки серого в пикселях изображений)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eMy5q_5F2h7b",
    "outputId": "7e74f8df-0c66-44e2-b6d5-e040cfa301bf"
   },
   "outputs": [],
   "source": [
    "encoded_train_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cyCF5GO4wsz"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(data, labels, output_filename):\n",
    "    \"\"\"Визуализация матрицы ошибок при помощи heatmap\n",
    " \n",
    "    Аргументы:\n",
    "        data (список списков): матрица ошибок (confusion matrix)\n",
    "        labels (список): Метки для осей x и y\n",
    "        output_filename (текст): Путь к выходному файлу\n",
    " \n",
    "    \"\"\"\n",
    "    sns.set(color_codes=True)\n",
    "    plt.figure(1, figsize=(9, 6))\n",
    " \n",
    "    sns.set(font_scale=1.3)\n",
    "    ax = sns.heatmap(data, annot=True, cmap=\"Blues\", \n",
    "                     cbar_kws={'label': 'Шкала'},fmt='d')\n",
    " \n",
    "    ax.set_xticklabels(labels, fontsize = 16)\n",
    "    ax.set_yticklabels(labels, fontsize = 16)\n",
    " \n",
    "    ax.set_xlabel(\"Прогнозные метки\", fontsize = 16)\n",
    "    ax.set_ylabel(\"Истинные метки\", fontsize = 16)\n",
    " \n",
    "    plt.savefig(output_filename, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ShVpu23L35jj"
   },
   "outputs": [],
   "source": [
    "# импорт необходимых библиотек \n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlagb73X2xm4"
   },
   "source": [
    "Обучим классификатор на закодированных изображениях и измерим, сколько времени потребуется для обучения. Позже сделаем то же самое с исходным набором данных и сравним результаты и время выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "PEZuHJg8ff7j",
    "outputId": "d72011ff-2c04-4c78-ace5-653577c58d4e"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    " \n",
    "# обучаем классификатор KNN \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7).fit(encoded_train_imgs, \n",
    "                                              mnist_y_train) \n",
    "  \n",
    "# доля верных ответов на X_test \n",
    "accuracy = knn.score(encoded_imgs, mnist_y_test) \n",
    "print (accuracy )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Время работы\",end - start,\"сек.\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "huxTT5p03CQ1"
   },
   "source": [
    "Всего с 8 признаками получаем 89% точности за несколько секунд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 401
    },
    "id": "XJXa2Oye40K_",
    "outputId": "823078e0-392c-409d-e3fa-ba96061a18e6"
   },
   "outputs": [],
   "source": [
    "# строим матрицу ошибок \n",
    "knn_predictions = knn.predict(encoded_imgs)  \n",
    "\n",
    "cm = confusion_matrix(mnist_y_test, knn_predictions)\n",
    "\n",
    "plot_confusion_matrix(cm, [0,1,2,3,4,5,6,7,8,9], \n",
    "                      \"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUySdOkeaA_X"
   },
   "source": [
    "### Алгоритм kNN со всеми признаками\n",
    "\n",
    "Теперь давайте обучим классификатор со всеми 784 признаками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "gXhGvgfpaDie",
    "outputId": "a199fa69-4bd4-4cde-a27d-533314d16abe"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    " \n",
    "knn2 = KNeighborsClassifier(n_neighbors = 7).fit(\n",
    "    mnist_x_trainMLP, mnist_y_train) \n",
    "\n",
    "# доля верных ответов на X_test \n",
    "accuracy = knn2.score(mnist_x_testMLP, mnist_y_test)  \n",
    "print (accuracy )\n",
    "\n",
    "end = time.time()\n",
    "print(\"Время работы\",end - start,\"sec.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-c0ZVIw3TfH"
   },
   "source": [
    "Со всеми признаками получаем точность 96% (на 7% больше, чем с 8 признаками), но это занимает больше времени. Для большого набора данных разница может быть гораздо более существенной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVvL5CtKooYi"
   },
   "source": [
    "## Функция потерь MSE\n",
    "\n",
    "Автокодировщики настолько гибки, что работают, даже если мы используем в качестве функции потерь MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CHeZ-jh-pIHN"
   },
   "outputs": [],
   "source": [
    "dim = 16\n",
    "\n",
    "input_img = Input(shape = (784,))\n",
    "encoded = Dense(dim, activation = 'relu')(input_img)\n",
    "decoded = Dense(784, activation = 'sigmoid')(encoded)\n",
    "\n",
    "autoencoderMSE = Model(input_img, decoded)\n",
    "encoderMSE = Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yne4LJ5Qprml"
   },
   "outputs": [],
   "source": [
    "encoded_input = Input(shape = (dim,))\n",
    "decoder = autoencoderMSE.layers[-1]\n",
    "decoderMSE = Model(encoded_input, decoder(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x25we9gypuQ8"
   },
   "outputs": [],
   "source": [
    "autoencoderMSE.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Wv5Cb89pwU7",
    "outputId": "c377cadc-0cda-4bb4-8a1a-f618863574d4"
   },
   "outputs": [],
   "source": [
    "autoencoderMSE.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(mnist_x_testMLP, mnist_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eWvGMfR5pzBq"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoderMSE.predict(mnist_x_testMLP)\n",
    "decoded_imgs = decoderMSE.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(mnist_x_testMLP, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBAq_uiwp3wt"
   },
   "source": [
    "## Набор данных Fashion MNIST\n",
    "\n",
    "Используем автокодировщик с 8 нейронами в среднем слое с набором данных FASHION MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CH-E8OZ-s44c",
    "outputId": "f779247f-de33-4f51-f5bf-524eb35541db"
   },
   "outputs": [],
   "source": [
    "autoencoder8, encoder8, decoder8 = create_autoencoders(8)\n",
    "autoencoder8.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder8.fit(fashion_x_trainMLP, fashion_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(fashion_x_testMLP, fashion_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcChJ6NCtYr1"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder8.predict(fashion_x_testMLP)\n",
    "decoded_imgs = decoder8.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_show(fashion_x_testMLP, decoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SGHRd1tCobZ"
   },
   "source": [
    "Снова построим классификатор со всеми данными:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "L1nP0LVDtT-3",
    "outputId": "23f39ad6-0497-4956-9faa-b7ada398611a"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(\n",
    "    fashion_x_trainMLP, fashion_y_train) \n",
    "\n",
    "# Доля верных ответов на X_test \n",
    "accuracy = knn.score(fashion_x_testMLP, fashion_y_test) \n",
    "print (accuracy )\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z1rIeQ-iEJT"
   },
   "source": [
    "## Алгоритм kNN на обученном представлении"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YL9BbtyRh23b"
   },
   "outputs": [],
   "source": [
    "encoded_fashion_train_imgs = encoder8.predict(fashion_x_trainMLP)\n",
    "encoded_fashion_test_imgs = encoder8.predict(fashion_x_testMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "FS2Q4_AKiL5-",
    "outputId": "445a363f-a790-4736-b559-6d6af3e7b9f8"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    " \n",
    "# обучаем классификатор KNN \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(\n",
    "    encoded_fashion_train_imgs, fashion_y_train) \n",
    "  \n",
    "# доля верных ответов на X_test \n",
    "accuracy = knn.score(encoded_fashion_test_imgs, fashion_y_test) \n",
    "print (accuracy )\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdEdeWCLEt-O"
   },
   "source": [
    "Опять теряем около 5% доли верных ответов за счет существенного ускорения работы. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EopH1TOuiX7J"
   },
   "source": [
    "## Доля верных ответов для kNN с автокодировщиком с количеством нейронов $(784,16,784)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "8PPfUo28mIgX",
    "outputId": "b511b835-6d65-4862-c043-b3b83cd46150"
   },
   "outputs": [],
   "source": [
    "autoencoder16, encoder16, decoder16 = create_autoencoders(16)\n",
    "autoencoder16.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder16.fit(fashion_x_trainMLP, fashion_x_trainMLP,\n",
    "                epochs=30,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(fashion_x_testMLP, fashion_x_testMLP),\n",
    "                verbose = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuAhbpAQmJqN"
   },
   "outputs": [],
   "source": [
    "encoded_fashion_train_imgs = encoder16.predict(fashion_x_trainMLP)\n",
    "encoded_fashion_test_imgs = encoder16.predict(fashion_x_testMLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "44ogzPh1mO9l",
    "outputId": "6ac24859-4024-44d5-97c1-9f9f16b533cb"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    " \n",
    "# обучение классификатора KNN \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(\n",
    "    encoded_fashion_train_imgs, fashion_y_train) \n",
    "  \n",
    "# доля верных ответов на X_test \n",
    "accuracy = knn.score(encoded_fashion_test_imgs, fashion_y_test) \n",
    "print (accuracy )\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It2Kf7opE7Pm"
   },
   "source": [
    "Увеличение количества нейронов в среднем слое до 16 увеличивает долю верных ответов при незначительном увеличении времени работы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обнаружение аномалий при помощи автокодировщиков\n",
    "\n",
    "Разберемся, что означает обнаружение аномалий. Создадим специальный набор данных, состоящий из 10000 изображений тестового набора данных MNIST и одного изображения из набора данных Fashion MNIST. Нашей целью будет найти это изображение автоматически. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4447,
     "status": "ok",
     "timestamp": 1614779661214,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "_GLwQBJiKN8s",
    "outputId": "441993e9-0ec0-41ab-fd35-8bbc2be2e981"
   },
   "outputs": [],
   "source": [
    "x_test = np.concatenate((mnist_x_testMLP, \n",
    "                         fashion_x_testMLP[0].reshape(1,784)))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSyL2zo_hKbM"
   },
   "source": [
    "Все изображения в наборе данных MNIST представляют собой написанные от руки цифры. Ниже вы можете увидеть пример одного из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_show(img):\n",
    "    plt.gray()\n",
    "    plt.tick_params(axis = 'x', which = 'both', bottom = False, \n",
    "                    top = False, labelbottom = False) \n",
    "    plt.tick_params(axis = 'y', which = 'both', left = False, \n",
    "                    right = False, labelleft = False)\n",
    "\n",
    "    plt.imshow(img.reshape(28, 28))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_show(mnist_x_test[10]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Fhf2JhchV2L"
   },
   "source": [
    "Но изображения в Fashion MNIST — это все изображения оттенками серого предметов одежды. В частности, мы добавляем к рукописным цифрам изображение обуви, которое можно увидеть ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_show(fashion_x_test[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6juVqpJvSQg"
   },
   "source": [
    "## Автокодировщик со слоями с $(784,64,784)$  нейронами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U5BaDqnbuY-I"
   },
   "outputs": [],
   "source": [
    "autoencoder64, encoder64, decoder64 = create_autoencoders(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 5291,
     "status": "ok",
     "timestamp": 1614779662083,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "A157gXaewJI2",
    "outputId": "deb4d8e3-564d-448d-df14-dbcd9fb2719d"
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(autoencoder64, show_shapes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rFv4sGg4mBkB"
   },
   "outputs": [],
   "source": [
    "autoencoder64.compile(optimizer = 'adam', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxaS4XlLmLI7"
   },
   "outputs": [],
   "source": [
    "history = autoencoder64.fit(mnist_x_trainMLP, mnist_x_trainMLP,\n",
    "                          epochs = 30,\n",
    "                          batch_size = 256,\n",
    "                          shuffle = True,\n",
    "                          validation_data = (mnist_x_testMLP, mnist_x_testMLP),\n",
    "                          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZaRLBur6mM2Y"
   },
   "outputs": [],
   "source": [
    "encoded_imgs = encoder64.predict(x_test)\n",
    "decoded_imgs = decoder64.predict(encoded_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YHCL4ik4jmFe"
   },
   "source": [
    "Теперь мы можем рассчитать ошибку реконструкции ($\\textrm{RE}^{[j]}$) изображения $j$, просто вычислив\n",
    "\n",
    "$$\n",
    "\\textrm{RE}^{[j]} = \\sum_{i=1}^{784}\\frac{(x_i^{[j]}-x_{rec,i}^{[j]})^2}{m}\n",
    "$$\n",
    "\n",
    "где $x_i^{[j]}$ — это значение $i^{го}$ пикселя изображения $j$, а сумма вычисляется по всем пикселям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jNXEYaZ6Lbkq"
   },
   "outputs": [],
   "source": [
    "RE = ((x_test - decoded_imgs)**2).mean(axis = 1)\n",
    "RE_original = RE.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hokL18o5kRvm"
   },
   "source": [
    "Ошибка реконструкции $\\textrm{RE}$ для изображения обуви, которое мы добавили, может быть легко выведена, так как это последний элемент вектора ```RE```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86119,
     "status": "ok",
     "timestamp": 1614779742928,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "Bqn_iVeTLnFA",
    "outputId": "4423a881-f95a-4e0a-a9a4-1ab7b25eb01f"
   },
   "outputs": [],
   "source": [
    "RE[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3labzutkjVB"
   },
   "source": [
    "Легко видеть, что это самая высокая ошибка реконструкции $\\textrm{RE}$, которая у нас есть для всех 10000 изображений. Мы можем проверить это, отсортировав вектор ```RE```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86115,
     "status": "ok",
     "timestamp": 1614779742929,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "CTrqrzhbMJ5q",
    "outputId": "485c2ad8-f5b2-4fad-a058-34a6e7e79ecc"
   },
   "outputs": [],
   "source": [
    "RE.sort()\n",
    "print(RE[9990:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sRpAOMlkui1"
   },
   "source": [
    "Вы можете видеть, что вторая по величине ошибка реконструкции составляет менее половины $\\textrm{RE}$ для добавленного изображения. Ниже вы можете увидеть исходное изображение и то, которое реконструировал обученный автокодировщик. Вы можете видеть, что восстановленное изображение совсем не похоже на оригинал."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2jQQDHzHsAI"
   },
   "source": [
    "### Самая большая ошибка реконструкции RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b__upD2l8Z1g"
   },
   "outputs": [],
   "source": [
    "biggest_re_pos = np.argmax(RE_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 86818,
     "status": "ok",
     "timestamp": 1614779743642,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "j6sjK8n9NRVl",
    "outputId": "254c7cc8-aac0-4656-db94-d92dde930df0"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14, 7))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.title('Исходное изображение', fontsize = 16)\n",
    "mnist_show(x_test[biggest_re_pos])\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.title('Реконструированное изображение', fontsize = 16)\n",
    "mnist_show(decoded_imgs[biggest_re_pos]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LfpTaJlBmgg4"
   },
   "source": [
    "Как вы можете видеть ниже, автокодировщик способен идеально реконструировать рукописные изображения цифр."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StYQJckJHv3m"
   },
   "source": [
    "### Вторая по величине ошибка реконструкции RE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDtyEeAXnBRe"
   },
   "source": [
    "Изображение, показанное ниже (и его реконструированная версия), имеет вторую по величине ошибку реконструкции. Причина ясна, это изображение совсем не похоже на рукописную цифру! Это может даже считаться выбросом в наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPRv13ZT8y0M"
   },
   "outputs": [],
   "source": [
    "second_biggest_re_pos = list(RE_original).index(RE[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 422
    },
    "executionInfo": {
     "elapsed": 87288,
     "status": "ok",
     "timestamp": 1614779744121,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "u9_acZDBnNFB",
    "outputId": "bd192934-9dff-43be-d7fb-4eba84546e3c"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14, 7))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.title('Исходное изображение', fontsize = 16)\n",
    "mnist_show(x_test[second_biggest_re_pos])\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.title('Реконструированное изображение', fontsize = 16)\n",
    "mnist_show(decoded_imgs[second_biggest_re_pos]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oin4zHzcHzp8"
   },
   "source": [
    "### Третья по величине ошибка реконструкции RE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MIbElKvfXKv3"
   },
   "outputs": [],
   "source": [
    "third_biggest_re_pos = list(RE_original).index(RE[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "executionInfo": {
     "elapsed": 87916,
     "status": "ok",
     "timestamp": 1614779744757,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "40eSJMeDNXnp",
    "outputId": "becaaa9b-fc23-434f-a4ff-ed63d1d43624"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (14, 7))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.title('Исходное изображение', fontsize = 16)\n",
    "mnist_show(x_test[third_biggest_re_pos])\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.title('Реконструированное изображение', fontsize = 16)\n",
    "mnist_show(decoded_imgs[third_biggest_re_pos]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подавление шумов изображений с помощью автокодировщиков на основе нейронных сетей MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n0Mwf3Zhfnnq"
   },
   "source": [
    "Используем [набор данных MNIST](http://yann.lecun.com/exdb/mnist/). Импортируем его из `keras` при помощи [```tensorflow.keras.datasets```](https://www.tensorflow.org/api_docs/python/tf/keras/datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2596,
     "status": "ok",
     "timestamp": 1615226493583,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "1C_DLqCRLNHs",
    "outputId": "cfcc3fa6-9ce2-48f6-e9a4-8c83a69ccb85"
   },
   "outputs": [],
   "source": [
    "# Загружаем набор данных MNIST\n",
    "(input_train, target_train), (input_test, target_test) = \\\n",
    "    mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Mqnau0AgM1G"
   },
   "source": [
    "Выполним типовую нормализацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHzORnSYgIu2"
   },
   "outputs": [],
   "source": [
    "# Переводим числа в тип float32\n",
    "input_train = input_train.astype('float32')\n",
    "input_test = input_test.astype('float32')\n",
    "\n",
    "# Нормализуем данные\n",
    "input_train = input_train / 255.\n",
    "input_test = input_test / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yHzORnSYgIu2"
   },
   "outputs": [],
   "source": [
    "# Изменим форму для сетей MLP\n",
    "input_trainMLP = input_train.reshape(\n",
    "    (len(input_train), np.prod(input_train.shape[1:])))\n",
    "input_testMLP = input_test.reshape(\n",
    "    (len(input_test), np.prod(input_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zQmozOX0h3tA"
   },
   "outputs": [],
   "source": [
    "# Изменим форму для сетей CNN\n",
    "img_width, img_height = 28, 28\n",
    "\n",
    "input_trainCNN = input_train.reshape(\n",
    "    input_train.shape[0], img_width, img_height, 1)\n",
    "input_testCNN = input_test.reshape(\n",
    "    input_test.shape[0], img_width, img_height, 1)\n",
    "input_shapeCNN = (img_width, img_height, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr4I-Jwn_rlG"
   },
   "source": [
    "Построим пример изображения для каждого возможного класса (то есть цифр от 0 до 9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jiC-adzw_uku"
   },
   "outputs": [],
   "source": [
    "from random import *\n",
    "\n",
    "def get_random_element_with_label (data, lbls, lbl):\n",
    "    \"\"\"Возвращает массив numpy (с одним столбцом) \n",
    "    с экземплярами выбранной метки.\"\"\"\n",
    "\n",
    "    tmp = lbls == lbl\n",
    "    subset = data[tmp.flatten(), :]\n",
    "    return subset[randint(0, subset.shape[0]), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vASz2W66_vFl"
   },
   "outputs": [],
   "source": [
    "# Изменяем форму обучающего набора данных\n",
    "input_example = input_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "96znRF-9_wuh"
   },
   "outputs": [],
   "source": [
    "# Следующий код создает массив numpy, где в столбце 0 будет\n",
    "# пример метки 0, в столбце 1 метки 1 и так далее.\n",
    "labels_overview = np.empty([784, 10])\n",
    "for i in range (0, 10):\n",
    "    col = get_random_element_with_label(\n",
    "        input_example, target_train, i)\n",
    "    labels_overview[:,i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "executionInfo": {
     "elapsed": 3415,
     "status": "ok",
     "timestamp": 1615226494420,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "6eZz6RlL_y4A",
    "outputId": "eaef274a-8754-4d96-dce8-c201b2bb1f21"
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize = (15, 15))\n",
    "count = 1\n",
    "for i in range(0, 10):\n",
    "    plt.gray()\n",
    "    plt.subplot(5, 2, count)\n",
    "    count = count + 1\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "    plt.title('Цифра: ' + str(i))\n",
    "    some_digit_image = labels_overview[:, i]\n",
    "    plt.imshow(some_digit_image.reshape(28, 28))\n",
    "    plt.axis('off')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piG2KgRbiIl6"
   },
   "source": [
    "## Добавление шума в набор данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABXvaRHZiatd"
   },
   "source": [
    "Добавим источник шума к изображениям MNIST (с помощью функции `np.random.normal`), так как нашей целью будет удалить из них этот шум."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0g8GDDmVLRj0"
   },
   "outputs": [],
   "source": [
    "noise_factor = 0.55\n",
    "pure = input_trainMLP\n",
    "pure_test = input_testMLP\n",
    "noise = np.random.normal(0, 1, pure.shape)\n",
    "noise_test = np.random.normal(0, 1, pure_test.shape)\n",
    "noisy_input = pure + noise_factor * noise\n",
    "noisy_input_test = pure_test + noise_factor * noise_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAPST0Y7_4ob"
   },
   "source": [
    "Теперь нарисуем несколько примеров изображений, искаженных шумом (по одному для каждого класса)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lZrPemCv_7g2"
   },
   "outputs": [],
   "source": [
    "# Следующий код создает массив numpy, где в столбце 0 будет\n",
    "# пример метки 0, в столбце 1 метки 1 и так далее.\n",
    "labels_overview = np.empty([784, 10])\n",
    "for i in range (0, 10):\n",
    "    col = get_random_element_with_label(\n",
    "        noisy_input, target_train, i)\n",
    "    labels_overview[:,i] = col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "executionInfo": {
     "elapsed": 6403,
     "status": "ok",
     "timestamp": 1615226497420,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "CRrrw1We_8_2",
    "outputId": "cacb98a7-8b28-4a35-dac5-384b021a6adf"
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize = (15, 15))\n",
    "count = 1\n",
    "for i in range(0, 10):\n",
    "    plt.gray()\n",
    "    plt.subplot(5, 2, count)\n",
    "    count = count + 1\n",
    "    plt.subplots_adjust(hspace = 0.5)\n",
    "    plt.title('Цифра: ' + str(i))\n",
    "    some_digit_image = labels_overview[:, i]\n",
    "    plt.imshow(some_digit_image.reshape(28, 28))\n",
    "    plt.axis('off')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L72cifjZhkwP"
   },
   "source": [
    "## Автокодировщик на базе сетей MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObIjY7x8LVMU"
   },
   "outputs": [],
   "source": [
    "autoencoder32, encoder32, decoder32 = create_autoencoders(32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11537,
     "status": "ok",
     "timestamp": 1615226502573,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "Qt94yvSJjxr8",
    "outputId": "60706e80-92ec-415d-f8ef-0fa16aa0aac1"
   },
   "outputs": [],
   "source": [
    "autoencoder32.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "executionInfo": {
     "elapsed": 12015,
     "status": "ok",
     "timestamp": 1615226503062,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "KOITmaI4jzKl",
    "outputId": "0eb547a7-bb0b-46aa-e934-25e5d190fd9e"
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(autoencoder32, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZr3qpqQj7zL"
   },
   "source": [
    "Воспользуемся следующими параметрами для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i33gwUO9LGkY"
   },
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "no_epochs = 30\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40477,
     "status": "ok",
     "timestamp": 1615226531536,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "6zDNq0Hwjep6",
    "outputId": "8a3bbcd7-7cf5-4a9b-f264-3b89226e4570"
   },
   "outputs": [],
   "source": [
    "autoencoder32.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "autoencoder32.fit(noisy_input, pure,\n",
    "                epochs = no_epochs,\n",
    "                batch_size = batch_size,\n",
    "                validation_split = validation_split);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9m6GES1muBD"
   },
   "source": [
    "## Примеры изображений с подавленным шумом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "De9Y9gXSnKrC"
   },
   "source": [
    "Построим несколько примеров изображений с подавленным шумом, сравнивая их с исходными чистыми изображениями, чтобы увидеть, насколько хорошо работает встроенный автокодировщик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxP0ECkYnWyv"
   },
   "outputs": [],
   "source": [
    "# Построим изображения без шума\n",
    "number_of_visualizations = 6\n",
    "samples = noisy_input_test[:number_of_visualizations]\n",
    "targets = target_test[:number_of_visualizations]\n",
    "denoised_images = autoencoder32.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 41587,
     "status": "ok",
     "timestamp": 1615226532659,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "7V9LkCV2LZwq",
    "outputId": "12e07f4d-e9ce-4040-c5d2-9e315392b304"
   },
   "outputs": [],
   "source": [
    "# нарисуем изображения без шума\n",
    "for i in range(0, number_of_visualizations):\n",
    "    plt.gray()\n",
    "    # изображение и реконструкция\n",
    "    noisy_image = noisy_input_test[i].reshape(28, 28)\n",
    "    pure_image  = pure_test[i].reshape(28, 28)\n",
    "    denoised_image = denoised_images[i].reshape(28, 28)\n",
    "    input_class = targets[i]\n",
    "    # подготовка\n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(12, 7)\n",
    "    # выводим изображение и реконструкцию\n",
    "    axes[0].imshow(noisy_image)\n",
    "    axes[0].set_title('Изображение с шумом', fontsize = 16)\n",
    "    axes[0].get_xaxis().set_visible(False)\n",
    "    axes[0].get_yaxis().set_visible(False)\n",
    "    axes[1].imshow(pure_image)\n",
    "    axes[1].set_title('Чистое изображение', fontsize = 16)\n",
    "    axes[1].get_xaxis().set_visible(False)\n",
    "    axes[1].get_yaxis().set_visible(False)\n",
    "    axes[2].imshow(denoised_image)\n",
    "    axes[2].set_title('Изображение без шума', fontsize = 16)\n",
    "    axes[2].get_xaxis().set_visible(False)\n",
    "    axes[2].get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gLDHJldACe4"
   },
   "source": [
    "Как видно из приведенного выше рисунка, построенная нами модель может реконструировать исходную версию изображений зашумленных цифр. Если у вас есть новые зашумленные изображения того же типа, вы можете применить к ним модель и удалить шум с тех же изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukBQfV-2q4Ej"
   },
   "source": [
    "## Автокодировщик с нейронной сетью CNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8cQrpbFrEK6"
   },
   "source": [
    "Функция ```create_autoencoder_CNN()``` ниже возвращает модель автокодировщика на базе CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8XSGlFSsrwc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "def create_autoencoder_CNN(max_norm_value = 2.0):\n",
    "    # Создаем модель\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size = (3, 3), \n",
    "                     kernel_constraint = max_norm(max_norm_value), \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer = 'he_uniform', \n",
    "                     input_shape = input_shapeCNN))\n",
    "    model.add(Conv2D(32, kernel_size = (3, 3), \n",
    "                     kernel_constraint = max_norm(max_norm_value), \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer = 'he_uniform'))\n",
    "    model.add(Conv2DTranspose(32, kernel_size = (3,3), \n",
    "                     kernel_constraint = max_norm(max_norm_value), \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer = 'he_uniform'))\n",
    "    model.add(Conv2DTranspose(64, kernel_size = (3,3), \n",
    "                     kernel_constraint = max_norm(max_norm_value), \n",
    "                     activation = 'relu', \n",
    "                     kernel_initializer = 'he_uniform'))\n",
    "    model.add(Conv2D(1, kernel_size = (3, 3), \n",
    "                     kernel_constraint = max_norm(max_norm_value), \n",
    "                     activation = 'sigmoid', padding = 'same'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hyTQv1qqs5bC"
   },
   "outputs": [],
   "source": [
    "model = create_autoencoder_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "executionInfo": {
     "elapsed": 11280,
     "status": "ok",
     "timestamp": 1615225518665,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "pmycMpwes9CV",
    "outputId": "47393636-cfda-42b5-ac78-b303b57ccd2e"
   },
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сети CNN нужна другая форма входных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_input = noisy_input.reshape(\n",
    "    noisy_input.shape[0], img_width, img_height, 1)\n",
    "pure = pure.reshape(\n",
    "    pure.shape[0], img_width, img_height, 1)\n",
    "\n",
    "noisy_input.shape,pure.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MipeLI5_tH9D"
   },
   "source": [
    "Используем следующие параметры для обучения модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4kmXOWztMc9"
   },
   "outputs": [],
   "source": [
    "batch_size = 150\n",
    "no_epochs = 5\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 221116,
     "status": "ok",
     "timestamp": 1615225728512,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "ObIjY7x8LVMU",
    "outputId": "366d755d-4f03-4776-ea01-254217ac09fe"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy')\n",
    "model.fit(noisy_input, pure,\n",
    "          epochs = no_epochs,\n",
    "          batch_size = batch_size,\n",
    "          validation_split = validation_split);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2mOEwTlstZrF"
   },
   "source": [
    "## Примеры изображений с подавленным шумом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHkM4ZzOtelf"
   },
   "source": [
    "Построим несколько примеров изображений с подавленным шумом, сравнивая их с исходными чистыми изображениями, чтобы увидеть, насколько хорошо работает встроенный автокодировщик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_input_test = noisy_input_test.reshape(\n",
    "    noisy_input_test.shape[0], img_width, img_height, 1)\n",
    "pure_test = pure_test.reshape(\n",
    "    pure_test.shape[0], img_width, img_height, 1)\n",
    "\n",
    "noisy_input_test.shape, pure_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIJJ7T9Ctgm-"
   },
   "outputs": [],
   "source": [
    "# Построим изображения без шума\n",
    "number_of_visualizations = 6\n",
    "samples = noisy_input_test[:number_of_visualizations]\n",
    "targets = target_test[:number_of_visualizations]\n",
    "denoised_images = model.predict(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 222513,
     "status": "ok",
     "timestamp": 1615225729921,
     "user": {
      "displayName": "Michela Sperti",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gh7mD9r-1Xj0Qve63ZPZx9UHRv0PkVhL5ayiHNv=s64",
      "userId": "13210266879998244642"
     },
     "user_tz": -60
    },
    "id": "7V9LkCV2LZwq",
    "outputId": "3e5cd0f1-a5de-479c-ec0e-82fbcceba996"
   },
   "outputs": [],
   "source": [
    "for i in range(0, number_of_visualizations):\n",
    "    plt.gray()\n",
    "    \n",
    "    noisy_image = noisy_input_test[i][:, :, 0]\n",
    "    pure_image  = pure_test[i][:, :, 0]\n",
    "    denoised_image = denoised_images[i][:, :, 0]\n",
    "    input_class = targets[i]\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3)\n",
    "    fig.set_size_inches(12, 7)\n",
    "    \n",
    "    axes[0].imshow(noisy_image)\n",
    "    axes[0].set_title('Noisy image', fontsize = 16)\n",
    "    axes[0].get_xaxis().set_visible(False)\n",
    "    axes[0].get_yaxis().set_visible(False)\n",
    "    axes[1].imshow(pure_image)\n",
    "    axes[1].set_title('Pure image', fontsize = 16)\n",
    "    axes[1].get_xaxis().set_visible(False)\n",
    "    axes[1].get_yaxis().set_visible(False)\n",
    "    axes[2].imshow(denoised_image)\n",
    "    axes[2].set_title('Denoised image', fontsize = 16)\n",
    "    axes[2].get_xaxis().set_visible(False)\n",
    "    axes[2].get_yaxis().set_visible(False)\n",
    "    fig.suptitle(f'MNIST target = {input_class}')\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgUU9MHC8qEE"
   },
   "source": [
    "Как видно из приведенного выше рисунка, построенная нами модель может реконструировать исходную версию изображений зашумленных цифр. Если у вас есть новые зашумленные изображения того же типа, вы можете применить к ним модель и удалить шум с тех же изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание (10 баллов)\n",
    "\n",
    "Для закрепленного за Вами варианта работы:\n",
    "\n",
    "1.\tЗагрузите заданный в индивидуальном задании набор данных с изображениями из Tensorflow Datasets с разбиением на обучающую и тестовую выборки. Оставьте в обучающей и тестовой выборках диапазон классов, указанных в индивидуальном задании. Если изображения цветные (с тремя каналами), то перекодируйте их в одноцветные (оттенки серого).\r\n",
    "2.\tПостройте для набора данных график логарифмического правдоподобия профиля в зависимости от числа главных компонент и определите размерность латентного пространства.\r\n",
    "3.\tСоздайте и обучите на обучающей выборке автокодировщик архитектуры, указанной в индивидуальном задании, с размерностью скрытого представления, равной размерности латентного пространства, определенной в п.2. Подберите такие параметры, как функции активации, оптимизатор, начальная скорость обучения, размер мини-пакета и др. самостоятельно, обеспечивая обучение нейронных сетей. Визуализируйте несколько исходных и восстановленных автокодировщиком изображений. \r\n",
    "4.\tОцените качество модели автокодировщика на тестовой выборке по показателю, указанному в индивидуальном задании.\r\n",
    "5.\tОставьте в наборах изображения первых двух классов диапазона, указанного в индивидуальном задании первыми. Визуализируйте набор данных на плоскости, соответствующей двум первым латентным признакам, отображая точки различных классов разными цветами. Подпишите оси и рисунок, создайте легенду для классов набора данных.\r\n",
    "6.\tВыполните бинарную классификацию изображений по латентным (скрытым) признакам и всем признакам при помощи классификатора метода ближайших соседей (kNN). Оцените долю верных ответов (accuracy) для двух построенных классификаторов\r\n",
    "7.\tВизуализируйте ROC-кривые для построенных классификаторов на одном рисунке (с легендой) (Указание: используйте метод predict_proba() класса KNeighborsClassifier).\r\n",
    "8.\tВизуализируйте границы принятия решений классификатора kNN для латентных признаков на плоскости, соответствующей двум первым латентным признакам (для прочих латентных признаков задайте средние/медианные значения). \r\n",
    "9.\tОпределите на первоначальной тестовой выборке изображение, имеющее наибольшую ошибку реконструкции. Выведите для этого изображения первоначальное и реконструированное изображения. \r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Your first autoencoder with Keras.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
